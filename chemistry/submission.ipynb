{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-25T07:33:15.903689Z",
     "start_time": "2025-01-25T07:33:14.677819Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T07:33:16.771155Z",
     "start_time": "2025-01-25T07:33:16.757434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def masking(cr, img, x):\n",
    "    mask = cv2.inRange(img, np.array(cr[0]), np.array(cr[1]))\n",
    "    cl = mask[:, x]\n",
    "    try:\n",
    "        idx = np.where(cl > 0)[0][0]\n",
    "    except IndexError:\n",
    "        print(cr)\n",
    "        return 10000000\n",
    "    return idx\n",
    "\n",
    "\n",
    "def smooth(idx, h):\n",
    "    return max(1 - idx / h, 0)\n",
    "\n",
    "\n",
    "def get_data(image_label, x):  #此函数用于使用cv2提取在浓度为x时的产物比例. This function is used to extract the product ratio at a concentration of x using cv2.\n",
    "    # 读取图像，Read image\n",
    "    img = cv2.imread(f\"{image_label}\")\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot read the img: {image_label}.png\")\n",
    "\n",
    "    cropped_img = img[97:711,126:899]\n",
    "\n",
    "    # 获取裁剪后图像尺寸，Get the size of the cropped image\n",
    "    height, width = cropped_img.shape[:2]\n",
    "\n",
    "    # 将x值映射到图像像素坐标，Map the x value to the image pixel coordinates.\n",
    "    x_min, x_max = 2, 12  # 图像x轴范围，Image x-axis range.\n",
    "    x_pixel = int((x - x_min) * width / (x_max - x_min))\n",
    "\n",
    "    # 确保x_pixel在有效范围内，Ensure x_pixel is within the valid range.\n",
    "    x_pixel = max(0, min(x_pixel, width-1))\n",
    "\n",
    "    # 定义每种元素对应的颜色范围 (OpenCV读入自动默认BGR格式)，Define the color range corresponding to each element (OpenCV reads in BGR format by default).\n",
    "    color_ranges = {\n",
    "        'N2': ([160, 0, 0], [255, 140, 100]),       # 蓝色，Blue\n",
    "        'NH4_ion': ([0, 110, 250], [120, 170, 255]), # 橘黄色，Orange\n",
    "        'N2O': ([0, 160, 0], [150, 255, 150]),      # 绿色，Green\n",
    "        'NO': ([0, 0, 160], [100, 100, 255]),        # 红色，Red\n",
    "        'NO2': ([180, 100, 140], [200, 120, 160]),    # 紫色，Purple\n",
    "    }\n",
    "    #\n",
    "    smoothed_results = {'N2': smooth(masking(color_ranges['N2'], cropped_img, x_pixel), height),\n",
    "                        'NH4_ion': smooth(masking(color_ranges['NH4_ion'], cropped_img, x_pixel), height),\n",
    "                        'N2O': smooth(masking(color_ranges['N2O'], cropped_img, x_pixel), height),\n",
    "                        'NO': smooth(masking(color_ranges['NO'], cropped_img, x_pixel), height),\n",
    "                        'NO2': smooth(masking(color_ranges['NO2'], cropped_img, x_pixel), height)}\n",
    "\n",
    "    return (smoothed_results['N2'], smoothed_results['NH4_ion'], smoothed_results['N2O'],\n",
    "            smoothed_results['NO'], smoothed_results['NO2'])"
   ],
   "id": "cf5371a543495190",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T07:33:18.675555Z",
     "start_time": "2025-01-25T07:33:18.665042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datapath_train = \"/bohr/train-gvtn/v1/\"\n",
    "# datapath_train = \"\"\n",
    "input_csv_path_train = os.path.join(datapath_train + 'input_train.csv')\n",
    "ref_path = os.path.join(datapath_train + 'ref_result_train.csv')\n",
    "data_train = pd.read_csv(input_csv_path_train)\n",
    "ref_train = pd.read_csv(ref_path)\n",
    "\n",
    "\n",
    "class EnvDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, feature, ref):\n",
    "        super().__init__()\n",
    "        self.feature = feature\n",
    "        self.ref = ref\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.feature[idx], self.ref[idx]\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 8),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "707223ed2f951c06",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T07:33:20.724851Z",
     "start_time": "2025-01-25T07:33:20.676193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features = []\n",
    "refs = []\n",
    "for i in range(5):\n",
    "    features.append(get_data(os.path.join(datapath_train, data_train['File Name'][i]), data_train['c'][i]))\n",
    "    refs.append([ref_train['p_1'][i], ref_train['p_2'][i], ref_train['p_3'][i], ref_train['p_4'][i],\n",
    "                 ref_train['p_5'][i], ref_train['p_6'][i], ref_train['p_7'][i], ref_train['p_8'][i]])\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32)\n",
    "refs = torch.tensor(refs, dtype=torch.float32)\n",
    "\n",
    "print(features)\n",
    "print(refs)"
   ],
   "id": "5e1789841ae4b243",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([160, 0, 0], [255, 140, 100])\n",
      "([0, 110, 250], [120, 170, 255])\n",
      "([0, 110, 250], [120, 170, 255])\n",
      "tensor([[0.0554, 0.0016, 0.1091, 0.4870, 0.3502],\n",
      "        [0.0000, 0.0000, 0.0098, 0.3844, 0.6091],\n",
      "        [0.0293, 0.0000, 0.0749, 0.4300, 0.4674],\n",
      "        [0.1938, 0.2427, 0.1564, 0.3893, 0.0212],\n",
      "        [0.1531, 0.0130, 0.1889, 0.4625, 0.1857]])\n",
      "tensor([[2.7209, 0.7209, 0.2168, 0.3014, 0.0671, 0.0342, 0.0000, 1.3604],\n",
      "        [3.1030, 1.1030, 0.6645, 0.4187, 0.0099, 0.0000, 0.0000, 1.5515],\n",
      "        [2.8337, 0.8337, 0.3519, 0.3237, 0.0566, 0.0224, 0.0000, 1.4168],\n",
      "        [2.5049, 0.4281, 0.0066, 0.1231, 0.0492, 0.0616, 0.0769, 1.0988],\n",
      "        [2.5763, 0.5714, 0.0795, 0.1969, 0.0799, 0.0652, 0.0048, 1.2785]])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T07:34:31.348379Z",
     "start_time": "2025-01-25T07:33:23.992078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = EnvDataset(features, refs)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 40000\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for feature, ref in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(feature)\n",
    "        loss = criterion(pred, ref)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            pred = net(features)\n",
    "            loss = criterion(pred, refs)\n",
    "            print(f\"epoch: {epoch}, loss: {loss}\")"
   ],
   "id": "3108fae6e694b111",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.4476737976074219\n",
      "epoch: 100, loss: 0.1930593103170395\n",
      "epoch: 200, loss: 0.016677487641572952\n",
      "epoch: 300, loss: 0.015491415746510029\n",
      "epoch: 400, loss: 0.014125319197773933\n",
      "epoch: 500, loss: 0.012694112956523895\n",
      "epoch: 600, loss: 0.011224610731005669\n",
      "epoch: 700, loss: 0.009769524447619915\n",
      "epoch: 800, loss: 0.008401504717767239\n",
      "epoch: 900, loss: 0.007148941047489643\n",
      "epoch: 1000, loss: 0.005951192229986191\n",
      "epoch: 1100, loss: 0.004899120423942804\n",
      "epoch: 1200, loss: 0.003961133770644665\n",
      "epoch: 1300, loss: 0.003282382385805249\n",
      "epoch: 1400, loss: 0.002880636602640152\n",
      "epoch: 1500, loss: 0.0026600512210279703\n",
      "epoch: 1600, loss: 0.0024578191805630922\n",
      "epoch: 1700, loss: 0.0023010889999568462\n",
      "epoch: 1800, loss: 0.0021683776285499334\n",
      "epoch: 1900, loss: 0.002063232008367777\n",
      "epoch: 2000, loss: 0.0019644179847091436\n",
      "epoch: 2100, loss: 0.0018870480125769973\n",
      "epoch: 2200, loss: 0.0018661494832485914\n",
      "epoch: 2300, loss: 0.0017332652350887656\n",
      "epoch: 2400, loss: 0.0016873767599463463\n",
      "epoch: 2500, loss: 0.0016244929283857346\n",
      "epoch: 2600, loss: 0.001596617279574275\n",
      "epoch: 2700, loss: 0.0015254709869623184\n",
      "epoch: 2800, loss: 0.0014898448716849089\n",
      "epoch: 2900, loss: 0.0014526948798447847\n",
      "epoch: 3000, loss: 0.0014110674383118749\n",
      "epoch: 3100, loss: 0.001393630402162671\n",
      "epoch: 3200, loss: 0.0013394763227552176\n",
      "epoch: 3300, loss: 0.0013050686102360487\n",
      "epoch: 3400, loss: 0.0013442420167848468\n",
      "epoch: 3500, loss: 0.0012369590112939477\n",
      "epoch: 3600, loss: 0.0012465568725019693\n",
      "epoch: 3700, loss: 0.0011789731215685606\n",
      "epoch: 3800, loss: 0.001143982051871717\n",
      "epoch: 3900, loss: 0.0011299359612166882\n",
      "epoch: 4000, loss: 0.0010680981213226914\n",
      "epoch: 4100, loss: 0.0010382478358224034\n",
      "epoch: 4200, loss: 0.0010102147934958339\n",
      "epoch: 4300, loss: 0.0009688151185400784\n",
      "epoch: 4400, loss: 0.0009333485504612327\n",
      "epoch: 4500, loss: 0.0009175416198559105\n",
      "epoch: 4600, loss: 0.0008625659975223243\n",
      "epoch: 4700, loss: 0.0008333352161571383\n",
      "epoch: 4800, loss: 0.0007983180694282055\n",
      "epoch: 4900, loss: 0.0007744092727079988\n",
      "epoch: 5000, loss: 0.0007817415753379464\n",
      "epoch: 5100, loss: 0.0007469025440514088\n",
      "epoch: 5200, loss: 0.0007039891788735986\n",
      "epoch: 5300, loss: 0.0006780014955438673\n",
      "epoch: 5400, loss: 0.0006598856998607516\n",
      "epoch: 5500, loss: 0.0006398818222805858\n",
      "epoch: 5600, loss: 0.0006246507400646806\n",
      "epoch: 5700, loss: 0.0006348417955450714\n",
      "epoch: 5800, loss: 0.0005898104282096028\n",
      "epoch: 5900, loss: 0.0005880679236724973\n",
      "epoch: 6000, loss: 0.0005819484358653426\n",
      "epoch: 6100, loss: 0.0005481125554069877\n",
      "epoch: 6200, loss: 0.0005336468457244337\n",
      "epoch: 6300, loss: 0.0005342660006135702\n",
      "epoch: 6400, loss: 0.0005094126099720597\n",
      "epoch: 6500, loss: 0.0005053336499258876\n",
      "epoch: 6600, loss: 0.0004927226109430194\n",
      "epoch: 6700, loss: 0.0004684774612542242\n",
      "epoch: 6800, loss: 0.00045864254934713244\n",
      "epoch: 6900, loss: 0.00044998404337093234\n",
      "epoch: 7000, loss: 0.0004875602317042649\n",
      "epoch: 7100, loss: 0.0004252681974321604\n",
      "epoch: 7200, loss: 0.00042186881182715297\n",
      "epoch: 7300, loss: 0.00040594866732135415\n",
      "epoch: 7400, loss: 0.00039955167449079454\n",
      "epoch: 7500, loss: 0.0004165032005403191\n",
      "epoch: 7600, loss: 0.0003781512496061623\n",
      "epoch: 7700, loss: 0.0004028382245451212\n",
      "epoch: 7800, loss: 0.0003752604534383863\n",
      "epoch: 7900, loss: 0.00036228931276127696\n",
      "epoch: 8000, loss: 0.00035226429463364184\n",
      "epoch: 8100, loss: 0.0003455672413110733\n",
      "epoch: 8200, loss: 0.00034105911618098617\n",
      "epoch: 8300, loss: 0.0003357165842317045\n",
      "epoch: 8400, loss: 0.00032835808815434575\n",
      "epoch: 8500, loss: 0.0003234570031054318\n",
      "epoch: 8600, loss: 0.0003140862681902945\n",
      "epoch: 8700, loss: 0.00031247991137206554\n",
      "epoch: 8800, loss: 0.0003100042522419244\n",
      "epoch: 8900, loss: 0.0003029240760952234\n",
      "epoch: 9000, loss: 0.00030791619792580605\n",
      "epoch: 9100, loss: 0.00029746181098744273\n",
      "epoch: 9200, loss: 0.0003058787842746824\n",
      "epoch: 9300, loss: 0.00031068825046531856\n",
      "epoch: 9400, loss: 0.00028999074129387736\n",
      "epoch: 9500, loss: 0.0002938652178272605\n",
      "epoch: 9600, loss: 0.00027908850461244583\n",
      "epoch: 9700, loss: 0.0002962180878967047\n",
      "epoch: 9800, loss: 0.00027820980176329613\n",
      "epoch: 9900, loss: 0.00027507886989042163\n",
      "epoch: 10000, loss: 0.0002732420398388058\n",
      "epoch: 10100, loss: 0.0002683463098946959\n",
      "epoch: 10200, loss: 0.00026388108381070197\n",
      "epoch: 10300, loss: 0.00027571761165745556\n",
      "epoch: 10400, loss: 0.00026831310242414474\n",
      "epoch: 10500, loss: 0.0002578519925009459\n",
      "epoch: 10600, loss: 0.000256559083936736\n",
      "epoch: 10700, loss: 0.00025309150805696845\n",
      "epoch: 10800, loss: 0.000261867098743096\n",
      "epoch: 10900, loss: 0.0002754866436589509\n",
      "epoch: 11000, loss: 0.0002568453492131084\n",
      "epoch: 11100, loss: 0.0002459264942444861\n",
      "epoch: 11200, loss: 0.0002597705752123147\n",
      "epoch: 11300, loss: 0.0002592897799331695\n",
      "epoch: 11400, loss: 0.00025701455888338387\n",
      "epoch: 11500, loss: 0.0002381730155320838\n",
      "epoch: 11600, loss: 0.00023869606957305223\n",
      "epoch: 11700, loss: 0.00023477838840335608\n",
      "epoch: 11800, loss: 0.00023321581829804927\n",
      "epoch: 11900, loss: 0.00023440000950358808\n",
      "epoch: 12000, loss: 0.0002360404032515362\n",
      "epoch: 12100, loss: 0.0002289850963279605\n",
      "epoch: 12200, loss: 0.0002269255492137745\n",
      "epoch: 12300, loss: 0.0002443438279442489\n",
      "epoch: 12400, loss: 0.00022221608378458768\n",
      "epoch: 12500, loss: 0.0002327702532056719\n",
      "epoch: 12600, loss: 0.00022343892487697303\n",
      "epoch: 12700, loss: 0.00022768575581721961\n",
      "epoch: 12800, loss: 0.00022142415400594473\n",
      "epoch: 12900, loss: 0.00021488410129677504\n",
      "epoch: 13000, loss: 0.00021501800802070647\n",
      "epoch: 13100, loss: 0.00024877412943169475\n",
      "epoch: 13200, loss: 0.00021086663764435798\n",
      "epoch: 13300, loss: 0.00020632446103263646\n",
      "epoch: 13400, loss: 0.00020729369134642184\n",
      "epoch: 13500, loss: 0.00020689234952442348\n",
      "epoch: 13600, loss: 0.00020814484742004424\n",
      "epoch: 13700, loss: 0.0002033100463449955\n",
      "epoch: 13800, loss: 0.00020258690346963704\n",
      "epoch: 13900, loss: 0.00019701931159943342\n",
      "epoch: 14000, loss: 0.00019656194490380585\n",
      "epoch: 14100, loss: 0.00019513335428200662\n",
      "epoch: 14200, loss: 0.00019382369646336883\n",
      "epoch: 14300, loss: 0.0002043924032477662\n",
      "epoch: 14400, loss: 0.00020114111248403788\n",
      "epoch: 14500, loss: 0.00020161243446636945\n",
      "epoch: 14600, loss: 0.0001878500188468024\n",
      "epoch: 14700, loss: 0.00019754059030674398\n",
      "epoch: 14800, loss: 0.00018470788199920207\n",
      "epoch: 14900, loss: 0.00018535509298089892\n",
      "epoch: 15000, loss: 0.00018975537386722863\n",
      "epoch: 15100, loss: 0.00017919184756465256\n",
      "epoch: 15200, loss: 0.00017868666327558458\n",
      "epoch: 15300, loss: 0.00017592475342098624\n",
      "epoch: 15400, loss: 0.00017466065764892846\n",
      "epoch: 15500, loss: 0.00017185536853503436\n",
      "epoch: 15600, loss: 0.00017283111810684204\n",
      "epoch: 15700, loss: 0.00017829827265813947\n",
      "epoch: 15800, loss: 0.0001865912927314639\n",
      "epoch: 15900, loss: 0.00017335817392449826\n",
      "epoch: 16000, loss: 0.00016559401410631835\n",
      "epoch: 16100, loss: 0.00018420771812088788\n",
      "epoch: 16200, loss: 0.00016529644199181348\n",
      "epoch: 16300, loss: 0.00016321880684699863\n",
      "epoch: 16400, loss: 0.00015914891264401376\n",
      "epoch: 16500, loss: 0.00015784389688633382\n",
      "epoch: 16600, loss: 0.00016142913955263793\n",
      "epoch: 16700, loss: 0.0001629188482183963\n",
      "epoch: 16800, loss: 0.0001560340024298057\n",
      "epoch: 16900, loss: 0.00015249449643306434\n",
      "epoch: 17000, loss: 0.00015870908100623637\n",
      "epoch: 17100, loss: 0.0001488871785113588\n",
      "epoch: 17200, loss: 0.00014840351650491357\n",
      "epoch: 17300, loss: 0.0001536340278107673\n",
      "epoch: 17400, loss: 0.00014430269948206842\n",
      "epoch: 17500, loss: 0.00014285172801464796\n",
      "epoch: 17600, loss: 0.0001497432531323284\n",
      "epoch: 17700, loss: 0.00014405632100533694\n",
      "epoch: 17800, loss: 0.00014013753389008343\n",
      "epoch: 17900, loss: 0.00015550032549072057\n",
      "epoch: 18000, loss: 0.00014232553075999022\n",
      "epoch: 18100, loss: 0.00013702388969250023\n",
      "epoch: 18200, loss: 0.0001345603377558291\n",
      "epoch: 18300, loss: 0.00013090265565551817\n",
      "epoch: 18400, loss: 0.00013114445027895272\n",
      "epoch: 18500, loss: 0.00013395657879300416\n",
      "epoch: 18600, loss: 0.00013287243200466037\n",
      "epoch: 18700, loss: 0.00012605474330484867\n",
      "epoch: 18800, loss: 0.00012605069787241518\n",
      "epoch: 18900, loss: 0.00012705777771770954\n",
      "epoch: 19000, loss: 0.0001225527812493965\n",
      "epoch: 19100, loss: 0.00011999659182038158\n",
      "epoch: 19200, loss: 0.00014222966274246573\n",
      "epoch: 19300, loss: 0.0001341152237728238\n",
      "epoch: 19400, loss: 0.00011541249841684476\n",
      "epoch: 19500, loss: 0.00011798448394984007\n",
      "epoch: 19600, loss: 0.00011301597987767309\n",
      "epoch: 19700, loss: 0.00011328914843033999\n",
      "epoch: 19800, loss: 0.0001101982343243435\n",
      "epoch: 19900, loss: 0.0001257430121768266\n",
      "epoch: 20000, loss: 0.00010695574019337073\n",
      "epoch: 20100, loss: 0.00011001542588928714\n",
      "epoch: 20200, loss: 0.00012218879419378936\n",
      "epoch: 20300, loss: 0.00010518155613681301\n",
      "epoch: 20400, loss: 0.00010639151878422126\n",
      "epoch: 20500, loss: 0.00010048943659057841\n",
      "epoch: 20600, loss: 9.86422091955319e-05\n",
      "epoch: 20700, loss: 9.850463538896292e-05\n",
      "epoch: 20800, loss: 0.00010212972847511992\n",
      "epoch: 20900, loss: 9.640892676543444e-05\n",
      "epoch: 21000, loss: 9.548310481477529e-05\n",
      "epoch: 21100, loss: 9.992443665396422e-05\n",
      "epoch: 21200, loss: 9.38375378609635e-05\n",
      "epoch: 21300, loss: 8.894015627447516e-05\n",
      "epoch: 21400, loss: 8.889381570043042e-05\n",
      "epoch: 21500, loss: 8.709631219971925e-05\n",
      "epoch: 21600, loss: 8.714730211067945e-05\n",
      "epoch: 21700, loss: 9.947724174708128e-05\n",
      "epoch: 21800, loss: 8.671380783198401e-05\n",
      "epoch: 21900, loss: 8.269102545455098e-05\n",
      "epoch: 22000, loss: 8.08644326752983e-05\n",
      "epoch: 22100, loss: 7.955657929414883e-05\n",
      "epoch: 22200, loss: 7.812424883013591e-05\n",
      "epoch: 22300, loss: 8.649877418065444e-05\n",
      "epoch: 22400, loss: 8.081052510533482e-05\n",
      "epoch: 22500, loss: 7.561473466921598e-05\n",
      "epoch: 22600, loss: 7.536068733315915e-05\n",
      "epoch: 22700, loss: 7.25267018424347e-05\n",
      "epoch: 22800, loss: 6.927387585164979e-05\n",
      "epoch: 22900, loss: 6.833310180809349e-05\n",
      "epoch: 23000, loss: 8.881155372364447e-05\n",
      "epoch: 23100, loss: 6.614992889808491e-05\n",
      "epoch: 23200, loss: 7.397987792501226e-05\n",
      "epoch: 23300, loss: 7.02294782968238e-05\n",
      "epoch: 23400, loss: 7.046815881039947e-05\n",
      "epoch: 23500, loss: 6.807837780797854e-05\n",
      "epoch: 23600, loss: 5.955111555522308e-05\n",
      "epoch: 23700, loss: 5.950548802502453e-05\n",
      "epoch: 23800, loss: 6.291460886131972e-05\n",
      "epoch: 23900, loss: 6.051919626770541e-05\n",
      "epoch: 24000, loss: 5.964825322735123e-05\n",
      "epoch: 24100, loss: 5.8237299526808783e-05\n",
      "epoch: 24200, loss: 5.247264198260382e-05\n",
      "epoch: 24300, loss: 5.220350431045517e-05\n",
      "epoch: 24400, loss: 4.932163210469298e-05\n",
      "epoch: 24500, loss: 5.22529189765919e-05\n",
      "epoch: 24600, loss: 4.7725938202347606e-05\n",
      "epoch: 24700, loss: 4.855884617427364e-05\n",
      "epoch: 24800, loss: 5.0791721150744706e-05\n",
      "epoch: 24900, loss: 4.3797823309432715e-05\n",
      "epoch: 25000, loss: 4.346128480392508e-05\n",
      "epoch: 25100, loss: 4.268366319593042e-05\n",
      "epoch: 25200, loss: 4.060460196342319e-05\n",
      "epoch: 25300, loss: 3.8263824535533786e-05\n",
      "epoch: 25400, loss: 5.072504427516833e-05\n",
      "epoch: 25500, loss: 5.359441274777055e-05\n",
      "epoch: 25600, loss: 4.213034480926581e-05\n",
      "epoch: 25700, loss: 4.068352063768543e-05\n",
      "epoch: 25800, loss: 3.452327291597612e-05\n",
      "epoch: 25900, loss: 4.167211227468215e-05\n",
      "epoch: 26000, loss: 3.529080277075991e-05\n",
      "epoch: 26100, loss: 2.9920676752226427e-05\n",
      "epoch: 26200, loss: 2.7967034839093685e-05\n",
      "epoch: 26300, loss: 3.0147721190587617e-05\n",
      "epoch: 26400, loss: 2.6827654437511228e-05\n",
      "epoch: 26500, loss: 2.7134748961543664e-05\n",
      "epoch: 26600, loss: 2.412388494121842e-05\n",
      "epoch: 26700, loss: 2.298389154020697e-05\n",
      "epoch: 26800, loss: 2.111409958160948e-05\n",
      "epoch: 26900, loss: 2.203479925810825e-05\n",
      "epoch: 27000, loss: 2.0760468032676727e-05\n",
      "epoch: 27100, loss: 2.0740973923238926e-05\n",
      "epoch: 27200, loss: 1.75706809386611e-05\n",
      "epoch: 27300, loss: 1.745999361446593e-05\n",
      "epoch: 27400, loss: 1.987193536479026e-05\n",
      "epoch: 27500, loss: 1.5166387129283976e-05\n",
      "epoch: 27600, loss: 1.5429801351274364e-05\n",
      "epoch: 27700, loss: 2.0761031919391826e-05\n",
      "epoch: 27800, loss: 1.294797857553931e-05\n",
      "epoch: 27900, loss: 1.3126744306646287e-05\n",
      "epoch: 28000, loss: 1.1533532415342052e-05\n",
      "epoch: 28100, loss: 1.2830680134356953e-05\n",
      "epoch: 28200, loss: 1.0075275895360392e-05\n",
      "epoch: 28300, loss: 9.678827154857572e-06\n",
      "epoch: 28400, loss: 1.0660213774826843e-05\n",
      "epoch: 28500, loss: 1.1513639947224874e-05\n",
      "epoch: 28600, loss: 8.4009316196898e-06\n",
      "epoch: 28700, loss: 1.044367854774464e-05\n",
      "epoch: 28800, loss: 1.1424568583606742e-05\n",
      "epoch: 28900, loss: 7.3848559623002075e-06\n",
      "epoch: 29000, loss: 7.5364491749496665e-06\n",
      "epoch: 29100, loss: 7.049030500638764e-06\n",
      "epoch: 29200, loss: 6.476142061728751e-06\n",
      "epoch: 29300, loss: 5.4372858357965015e-06\n",
      "epoch: 29400, loss: 4.492246262088884e-06\n",
      "epoch: 29500, loss: 4.765880930790445e-06\n",
      "epoch: 29600, loss: 5.231933755567297e-06\n",
      "epoch: 29700, loss: 3.737903625733452e-06\n",
      "epoch: 29800, loss: 4.878460458712652e-06\n",
      "epoch: 29900, loss: 4.699417331721634e-06\n",
      "epoch: 30000, loss: 3.998458851128817e-06\n",
      "epoch: 30100, loss: 2.9438085675792536e-06\n",
      "epoch: 30200, loss: 2.410969045740785e-06\n",
      "epoch: 30300, loss: 3.037290980500984e-06\n",
      "epoch: 30400, loss: 3.879808900819626e-06\n",
      "epoch: 30500, loss: 2.4672331164765637e-06\n",
      "epoch: 30600, loss: 2.0154000139882555e-06\n",
      "epoch: 30700, loss: 2.17292881643516e-06\n",
      "epoch: 30800, loss: 2.301001813975745e-06\n",
      "epoch: 30900, loss: 1.6340633237632574e-06\n",
      "epoch: 31000, loss: 1.9822884951281594e-06\n",
      "epoch: 31100, loss: 1.3923928463555058e-06\n",
      "epoch: 31200, loss: 1.967062189578428e-06\n",
      "epoch: 31300, loss: 1.0290750651620328e-06\n",
      "epoch: 31400, loss: 1.0750466117315227e-06\n",
      "epoch: 31500, loss: 1.4020372418599436e-06\n",
      "epoch: 31600, loss: 1.0219339401373873e-06\n",
      "epoch: 31700, loss: 7.449881991306029e-07\n",
      "epoch: 31800, loss: 7.375214181593037e-07\n",
      "epoch: 31900, loss: 2.1071195988042746e-06\n",
      "epoch: 32000, loss: 2.468557795509696e-06\n",
      "epoch: 32100, loss: 1.442248390048917e-06\n",
      "epoch: 32200, loss: 5.732332510888227e-07\n",
      "epoch: 32300, loss: 4.32073647971265e-07\n",
      "epoch: 32400, loss: 1.2421215842550737e-06\n",
      "epoch: 32500, loss: 4.862424702878343e-07\n",
      "epoch: 32600, loss: 4.3619061784738733e-07\n",
      "epoch: 32700, loss: 5.114147825224791e-06\n",
      "epoch: 32800, loss: 2.197414232796291e-07\n",
      "epoch: 32900, loss: 3.2886310918911477e-07\n",
      "epoch: 33000, loss: 2.1584897069715225e-07\n",
      "epoch: 33100, loss: 2.0924589705373364e-07\n",
      "epoch: 33200, loss: 1.334455106416499e-07\n",
      "epoch: 33300, loss: 4.6386767849071475e-07\n",
      "epoch: 33400, loss: 9.91689921647776e-06\n",
      "epoch: 33500, loss: 9.13056084073105e-08\n",
      "epoch: 33600, loss: 9.49643705894232e-08\n",
      "epoch: 33700, loss: 7.48811430639762e-08\n",
      "epoch: 33800, loss: 1.0774700598403797e-07\n",
      "epoch: 33900, loss: 8.174131949090224e-08\n",
      "epoch: 34000, loss: 4.367663919424558e-08\n",
      "epoch: 34100, loss: 4.421501742513101e-08\n",
      "epoch: 34200, loss: 1.6954314219219668e-07\n",
      "epoch: 34300, loss: 2.7019189019483747e-06\n",
      "epoch: 34400, loss: 2.6050082979622857e-08\n",
      "epoch: 34500, loss: 1.0391854488034369e-07\n",
      "epoch: 34600, loss: 2.0719262749935297e-07\n",
      "epoch: 34700, loss: 7.384643652130762e-08\n",
      "epoch: 34800, loss: 3.175682365963439e-07\n",
      "epoch: 34900, loss: 1.5043951862026006e-08\n",
      "epoch: 35000, loss: 1.0900022218152117e-08\n",
      "epoch: 35100, loss: 8.147370067490556e-07\n",
      "epoch: 35200, loss: 1.69058267829314e-07\n",
      "epoch: 35300, loss: 7.424501013986173e-09\n",
      "epoch: 35400, loss: 4.5850555352444644e-08\n",
      "epoch: 35500, loss: 1.93845330898057e-08\n",
      "epoch: 35600, loss: 3.8750243902541115e-07\n",
      "epoch: 35700, loss: 2.645463226258471e-08\n",
      "epoch: 35800, loss: 5.324793939109895e-09\n",
      "epoch: 35900, loss: 2.2977517666333824e-09\n",
      "epoch: 36000, loss: 7.250293947436148e-07\n",
      "epoch: 36100, loss: 3.4109948199301243e-09\n",
      "epoch: 36200, loss: 3.724559860529553e-08\n",
      "epoch: 36300, loss: 2.7992021145450963e-08\n",
      "epoch: 36400, loss: 5.174381456640731e-08\n",
      "epoch: 36500, loss: 2.655685005237274e-09\n",
      "epoch: 36600, loss: 2.5481261900495156e-07\n",
      "epoch: 36700, loss: 8.928752848191834e-09\n",
      "epoch: 36800, loss: 3.911461377015257e-08\n",
      "epoch: 36900, loss: 6.885579884041704e-10\n",
      "epoch: 37000, loss: 3.1542506384596436e-09\n",
      "epoch: 37100, loss: 3.7993055457263836e-07\n",
      "epoch: 37200, loss: 1.2750293763019727e-06\n",
      "epoch: 37300, loss: 3.36886323282215e-08\n",
      "epoch: 37400, loss: 2.2157207180129035e-09\n",
      "epoch: 37500, loss: 6.241484218350024e-09\n",
      "epoch: 37600, loss: 3.370368872879226e-08\n",
      "epoch: 37700, loss: 2.7651472223055862e-08\n",
      "epoch: 37800, loss: 2.3526749259872304e-07\n",
      "epoch: 37900, loss: 3.2187184473286834e-08\n",
      "epoch: 38000, loss: 2.2106965502644016e-07\n",
      "epoch: 38100, loss: 3.163763295788158e-08\n",
      "epoch: 38200, loss: 1.2956966610744303e-09\n",
      "epoch: 38300, loss: 4.32884590395588e-08\n",
      "epoch: 38400, loss: 6.53099050396122e-07\n",
      "epoch: 38500, loss: 4.968229383450762e-09\n",
      "epoch: 38600, loss: 1.4046477314622052e-09\n",
      "epoch: 38700, loss: 5.76327511225827e-06\n",
      "epoch: 38800, loss: 1.235122004672462e-09\n",
      "epoch: 38900, loss: 8.20145906743619e-09\n",
      "epoch: 39000, loss: 1.271866700847113e-08\n",
      "epoch: 39100, loss: 7.99104782345239e-09\n",
      "epoch: 39200, loss: 2.151818279116924e-09\n",
      "epoch: 39300, loss: 2.994737258177338e-07\n",
      "epoch: 39400, loss: 4.792704544342996e-08\n",
      "epoch: 39500, loss: 3.4419561645293584e-10\n",
      "epoch: 39600, loss: 1.0927228899504371e-08\n",
      "epoch: 39700, loss: 3.010978688600119e-10\n",
      "epoch: 39800, loss: 3.3995998904856606e-08\n",
      "epoch: 39900, loss: 3.55257974149481e-08\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T07:36:31.645743Z",
     "start_time": "2025-01-25T07:36:31.590148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#-------------读取测试集---------------#“DATA_PATH”是测试集加密后的环境变量，按照如下方式可以在提交后，系统评分时访问测试集，但是选手无法直接下载\n",
    "#----Read the testing set, “DATA_PATH” is an environment variable for the encrypted test set. After submission, you can access the test set for system scoring in the following manner, but the contestant cannot download it directly.-----#\n",
    "if os.environ.get('DATA_PATH'):\n",
    "    DATA_PATH = os.environ.get(\"DATA_PATH\") + \"/\"\n",
    "else:\n",
    "    print(\"Baseline运行时，因为无法读取测试集，所以会有此条报错，属于正常现象\")\n",
    "    print(\"When baseline is running, this error message will appear because the test set cannot be read, which is a normal phenomenon.\")\n",
    "    #Baseline运行时，因为无法读取测试集，所以会有此条报错，属于正常现象\n",
    "    #When baseline is running, this error message will appear because the test set cannot be read, which is a normal phenomenon.\n",
    "\n",
    "datapath_test = DATA_PATH\n",
    "# datapath_test = \"\"\n",
    "input_csv_path_test = os.path.join(datapath_test + 'input_test.csv')\n",
    "data_test = pd.read_csv(input_csv_path_test)\n",
    "\n",
    "#---对测试数据进行计算--Calculate on the test data----#\n",
    "output_data = [] # 用于存储测试集输出结果的列表，A list used to store the output results of the test set.\n",
    "\n",
    "# 遍历每一张图和x，Traverse each image and x.\n",
    "for index, row in data_test.iterrows():\n",
    "    image_label = os.path.join(datapath_test, row['File Name'])  # 获取文件名（不带扩展名）并与datapath连接\n",
    "    x_value = row['c']\n",
    "\n",
    "    # 调用get_data函数处理图像并获取结果，Invoke the get_data function to process the image and obtain the results.\n",
    "    results = get_data(image_label, x_value)\n",
    "\n",
    "    # 调用calculate函数计算值，Call the calculate function to compute the value.\n",
    "    pred = net(torch.tensor(results, dtype=torch.float32))\n",
    "    calculated_values = pred.detach().numpy()\n",
    "\n",
    "    # 将结果添加到输出数据中，Add the result to the output data.\n",
    "    output_data.append({\n",
    "        'File Name': row['File Name'],\n",
    "        'Scaled mol X': 1,\n",
    "        'p_1': calculated_values[0],\n",
    "        'p_2': calculated_values[1],\n",
    "        'Scaled mol X+': 1,\n",
    "        'p_3': calculated_values[2],\n",
    "        'p_4': calculated_values[3],\n",
    "        'p_5': calculated_values[4],\n",
    "        'p_6': calculated_values[5],\n",
    "        'p_7': calculated_values[6],\n",
    "        'p_8': calculated_values[7]\n",
    "    })\n",
    "\n",
    "# 创建输出DataFrame并保存为CSV文件，Create the output DataFrame and save it as a CSV file\n",
    "output_df = pd.DataFrame(output_data)\n",
    "output_csv_path = os.path.join('submission.csv')\n",
    "print(output_df)\n",
    "output_df.to_csv(output_csv_path, index=False)"
   ],
   "id": "7e8fde0301885439",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline运行时，因为无法读取测试集，所以会有此条报错，属于正常现象\n",
      "When baseline is running, this error message will appear because the test set cannot be read, which is a normal phenomenon.\n",
      "([160, 0, 0], [255, 140, 100])\n",
      "([0, 110, 250], [120, 170, 255])\n",
      "([0, 110, 250], [120, 170, 255])\n",
      "  File Name  Scaled mol X       p_1       p_2  Scaled mol X+       p_3  \\\n",
      "0    00.png             1  2.720835  0.720850              1  0.216815   \n",
      "1    27.png             1  3.103030  1.103048              1  0.664504   \n",
      "2    72.png             1  2.833675  0.833654              1  0.351929   \n",
      "3    77.png             1  2.504925  0.428070              1  0.006615   \n",
      "4    96.png             1  2.576205  0.571398              1  0.079499   \n",
      "\n",
      "        p_4       p_5       p_6       p_7       p_8  \n",
      "0  0.301398  0.067088  0.034252 -0.000021  1.360422  \n",
      "1  0.418671  0.009935  0.000004 -0.000002  1.551517  \n",
      "2  0.323679  0.056619  0.022401  0.000003  1.416836  \n",
      "3  0.123054  0.049171  0.061616  0.076841  1.098757  \n",
      "4  0.196845  0.079898  0.065234  0.004815  1.278452  \n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
