{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import astropy.io.fits as pyfits\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SMOOTHING = 3\n",
    "DEVICE = \"cuda\"\n",
    "DATA_DIR = \"\"\n",
    "BATCH_SIZE = 4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class AstroDataset(Dataset):\n",
    "    def __init__(self, map_paths, cat_paths=None):\n",
    "        self.map_paths = map_paths\n",
    "        self.cat_paths = cat_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.map_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image with gaussian smoothing\n",
    "        map_data = gaussian_filter(pyfits.open(self.map_paths[idx])[0].data, sigma=SMOOTHING)\n",
    "\n",
    "        if self.cat_paths is None:\n",
    "            return torch.FloatTensor(map_data).unsqueeze(0)\n",
    "\n",
    "        # Load catalog\n",
    "        cat = pyfits.open(self.cat_paths[idx])[0].data\n",
    "        target = np.zeros((1024, 1024))\n",
    "\n",
    "        for y, x in cat[:, 1:3]:\n",
    "            target[int(y), int(x)] = 1.0\n",
    "\n",
    "        return torch.FloatTensor(map_data).unsqueeze(0), torch.FloatTensor(target), self.cat_paths[idx]\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=15, padding=7),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=7, padding=3),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2, stride=1),\n",
    "            # nn.Conv2d(64, 1, kernel_size=1),\n",
    "            # nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(32, 1, kernel_size=1),\n",
    "            # nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "d44816e87a416839",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def detect_objects(model, image_path, confidence_threshold, device=DEVICE):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Load and preprocess image\n",
    "        map_data = gaussian_filter(pyfits.open(image_path)[0].data, sigma=SMOOTHING)\n",
    "        image = torch.FloatTensor(map_data).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        output = model(image)\n",
    "        predictions = output.cpu().squeeze().numpy()\n",
    "\n",
    "        # Convert to coordinates\n",
    "        coordinates = []\n",
    "        for y, x in zip(*np.where(predictions > confidence_threshold)):\n",
    "            confidence = predictions[y, x]\n",
    "            coordinates.append((x, y, confidence))\n",
    "\n",
    "        return coordinates\n",
    "\n",
    "# Visualizing model predictions 可视化模型输出\n",
    "def visualize_results(model, image_path, label_path, confidence_threshold, device=DEVICE):\n",
    "    # Get predictions with confidence scores\n",
    "    results = detect_objects(model, image_path, confidence_threshold, device)\n",
    "    results = np.array(results).T if results else np.array([[],[],[]])\n",
    "\n",
    "    Z = pyfits.open(image_path)[0].data\n",
    "    Z_smooth = gaussian_filter(Z, sigma=SMOOTHING)\n",
    "\n",
    "    labels = np.transpose(pyfits.open(label_path)[0].data)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(Z_smooth, vmin=-0.1, vmax=0.2, cmap='binary')\n",
    "    plt.scatter(labels[2], labels[1], facecolors='none', edgecolors='red', s=100, label=\"True\")\n",
    "    if len(results[0]) > 0:\n",
    "        # Color the scatter points based on confidence scores\n",
    "        plt.scatter(results[0], results[1], facecolors='none', edgecolors='green', s=100, label=\"Predicted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "Metric function for calculating PR-AUC.\n",
    "This exact function will be used for evaluation\n",
    "计算PR-AUC分数\n",
    "此原函数将用于比赛评测\n",
    "'''\n",
    "def calculate_precision_recall_curve(predictions, labels):\n",
    "\n",
    "    print(\"shape of predictions: \", predictions.shape)\n",
    "\n",
    "    # Flatten the predictions and get the indices of the sorted predictions\n",
    "    flat_predictions = predictions.flatten()\n",
    "    sorted_indices = np.argsort(-flat_predictions)  # Sort in descending order\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    true_preds = 0\n",
    "    num_preds = 0\n",
    "    predicted_labels = 0\n",
    "    num_labels = sum(len(l) for l in labels)\n",
    "\n",
    "    labels_within_distance = [[] for _ in range(len(flat_predictions))]\n",
    "\n",
    "    i = 0\n",
    "    for image_idx, image_labels in enumerate(labels):\n",
    "        for y_true, x_true in image_labels:\n",
    "            for y in range(max(0, int(y_true) - 15), min(1024, int(y_true) + 16)):\n",
    "                # Calculate the maximum x distance for the current y\n",
    "                max_x_dist = int((max(0, 15**2 - (y - y_true)**2))**0.5)\n",
    "                # Calculate the range of x-coordinates\n",
    "                for x in range(max(0, int(x_true) - max_x_dist), min(1024, int(x_true) + max_x_dist + 1)):\n",
    "                    coord_idx = image_idx * 1024 * 1024 + y * 1024 + x\n",
    "                    labels_within_distance[coord_idx].append(i)\n",
    "            i += 1\n",
    "\n",
    "    label_predicted = [False] * num_labels\n",
    "\n",
    "    # Iterate over sorted predictions\n",
    "    for idx in sorted_indices:\n",
    "\n",
    "        num_preds += 1\n",
    "\n",
    "        # Determine the image index and the coordinate within the image\n",
    "        image_idx = idx // (1024 * 1024)\n",
    "        coord_idx = idx % (1024 * 1024)\n",
    "        y, x = divmod(coord_idx, 1024)\n",
    "\n",
    "        if len(labels_within_distance[idx]) > 0:\n",
    "            true_preds += 1\n",
    "            for label in labels_within_distance[idx]:\n",
    "                if label_predicted[label] is False:\n",
    "                    label_predicted[label] = True\n",
    "                    predicted_labels += 1\n",
    "\n",
    "        # Calculate precision and recall\n",
    "        precision = true_preds / num_preds\n",
    "        recall = predicted_labels / num_labels\n",
    "\n",
    "        # Append precision and recall to the lists\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    # Calculate PR-AUC using the trapezoidal rule\n",
    "    pr_auc = np.trapz(precisions, x=recalls)\n",
    "\n",
    "    return precisions, recalls, pr_auc\n",
    "\n",
    "# Evaluate model 评测模型\n",
    "def get_pr(model, test_loader, device=DEVICE):\n",
    "    model.eval()\n",
    "    for images, _, paths in test_loader:\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).cpu().numpy().squeeze(1)\n",
    "            cat_data = [np.transpose(pyfits.open(path)[0].data) for path in paths]\n",
    "            labels = [list(zip(cat[1], cat[2])) for cat in cat_data]\n",
    "        return calculate_precision_recall_curve(outputs, labels)"
   ],
   "id": "b783b65a5688a2e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = torch.load('model0.5569.pth').to(DEVICE)",
   "id": "fc2ea2007386bd0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_size = len(os.listdir(os.path.join(DATA_DIR, 'map')))\n",
    "# Ensure correct data and label ordering\n",
    "dataset = AstroDataset([os.path.join(DATA_DIR, f'map/{i}.fits') for i in range(1, data_size+1)],\n",
    "                       [os.path.join(DATA_DIR, f'cat/{i}.fits') for i in range(1, data_size+1)])\n",
    "\n",
    "# Create data loader\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "id": "ec4581af43a0ce59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate PR-AUC 计算PR-AUC分数\n",
    "precisions, recalls, pr_auc = get_pr(model, dataloader)\n",
    "print(f\"PR-AUC Score: {pr_auc:.4f}\")\n",
    "\n",
    "# Plot PR curve 可视化精确率-召回率曲线\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall Curve (AUC = {pr_auc:.8f})')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "7643cc9785ccaccd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import zipfile\n",
    "\n",
    "if os.environ.get('DATA_PATH'):\n",
    "    # Submit testA for public leaderboard 提交选手公开傍结果\n",
    "    DATA_PATH = os.environ.get('DATA_PATH') + \"/\"\n",
    "    TEST_DATA_DIR = DATA_PATH + 'halo_testA'\n",
    "    test_size = len(os.listdir(os.path.join(TEST_DATA_DIR, 'map')))\n",
    "    dataset = AstroDataset([os.path.join(TEST_DATA_DIR, f'map/{i}.fits') for i in range(1, test_size+1)])\n",
    "    loader = DataLoader(dataset, batch_size=test_size, shuffle=False)\n",
    "    model.eval()\n",
    "    for images in loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images.to(DEVICE)).cpu().numpy().squeeze(1)\n",
    "        np.save('submissionsA.npy', outputs)\n",
    "    # Submit testB for private leaderboard 提交评测数据结果\n",
    "    TEST_DATA_DIR = DATA_PATH + 'halo_testB'\n",
    "    test_size = len(os.listdir(os.path.join(TEST_DATA_DIR, 'map')))\n",
    "    dataset = AstroDataset([os.path.join(TEST_DATA_DIR, f'map/{i}.fits') for i in range(1, test_size+1)])\n",
    "    loader = DataLoader(dataset, batch_size=test_size, shuffle=False)\n",
    "    model.eval()\n",
    "    for images in loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images.to(DEVICE)).cpu().numpy().squeeze(1)\n",
    "        np.save('submissionsB.npy', outputs)\n",
    "\n",
    "    # The final submission will be a zip file containing the your model outputs for both testing sets\n",
    "    # 最终提交一个压缩文件包括两个npy文件。\n",
    "    with zipfile.ZipFile('submission.zip', 'w') as zipf:\n",
    "        zipf.write('submissionsA.npy')\n",
    "        zipf.write('submissionsB.npy')"
   ],
   "id": "e6a1020ccb477e35",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
